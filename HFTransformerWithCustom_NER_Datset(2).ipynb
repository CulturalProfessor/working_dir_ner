{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQFCLASOTdDp"
      },
      "source": [
        "# Training Hugging Face Transformer model with Custom NER Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Eq6T2HuTa4h"
      },
      "source": [
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSJrwT_c-e9P",
        "outputId": "76192aa6-0c7c-46bf-9b5a-bb507ac28c28",
        "collapsed": true
      },
      "source": [
        "! pip install transformers datasets seqeval evaluate torch"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKE0HVk9TuFf",
        "outputId": "737ef27e-b65f-408f-bec7-ffdc257905bd"
      },
      "source": [
        "! ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hf_model_train.py  hf_tokenize.py  sample_data\tsroie2019_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python customExtractor.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkHziwAXqCQe",
        "outputId": "07fe468c-1474-4997-bfac-86ee0138eff6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing CSV into nested sequences...\n",
            "Processed 16047 sequences.\n",
            "Converting sequences to CoNLL format...\n",
            "Validating tags...\n",
            "Splitting data...\n",
            "Saving datasets as CoNLL text files...\n",
            "Dataset preparation completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPjtyBx1kQ8D",
        "outputId": "4abe63f9-9f2b-4671-be36-7472bc18be20",
        "collapsed": true
      },
      "source": [
        "!python hf_tokenize.py"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-26 13:33:09.618034: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-26 13:33:09.643056: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-26 13:33:09.650214: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-26 13:33:11.255454: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Map: 100% 124/124 [00:00<00:00, 454.85 examples/s]\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'tokens', 'ner_tags'],\n",
            "        num_rows: 124\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'tokens', 'ner_tags'],\n",
            "        num_rows: 124\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'tokens', 'ner_tags'],\n",
            "        num_rows: 124\n",
            "    })\n",
            "})\n",
            "****************************************************************************************************\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 124\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 124\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 124\n",
            "    })\n",
            "})\n",
            "First sample:  {'id': '0', 'tokens': ['+91', '89012', '34567', 'AMOUNT', 'PAID', '=', '834.82', 'D-MART', 'PVT', 'LTD', '35/2867', 'B', '&', 'B2', 'Bypass', 'Road', 'Opp', 'Oberon', 'Mall', '41HHLWE12K4A1Q6', 'Edappally', 'Kochi', 'Kerala', '682024'], 'ner_tags': [55, 18, 18, 31, 55, 55, 24, 55, 55, 55, 55, 55, 55, 55, 5, 26, 35, 35, 35, 55, 5, 5, 5, 18]}\n",
            "****************************************************************************************************\n",
            "First tokenized sample:  {'id': '0', 'tokens': ['+91', '89012', '34567', 'AMOUNT', 'PAID', '=', '834.82', 'D-MART', 'PVT', 'LTD', '35/2867', 'B', '&', 'B2', 'Bypass', 'Road', 'Opp', 'Oberon', 'Mall', '41HHLWE12K4A1Q6', 'Edappally', 'Kochi', 'Kerala', '682024'], 'ner_tags': [55, 18, 18, 31, 55, 55, 24, 55, 55, 55, 55, 55, 55, 55, 5, 26, 35, 35, 35, 55, 5, 5, 5, 18], 'input_ids': [101, 1009, 6205, 6486, 24096, 2475, 23785, 2575, 2581, 3815, 3825, 1027, 6640, 2549, 1012, 6445, 1040, 1011, 20481, 26189, 2102, 5183, 3486, 1013, 24921, 2581, 1038, 1004, 1038, 2475, 11826, 2346, 6728, 2361, 15578, 4948, 6670, 4601, 23644, 2140, 8545, 12521, 2243, 2549, 27717, 4160, 2575, 3968, 29098, 3973, 27603, 8935, 6273, 11387, 18827, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 55, 55, 18, 18, 18, 18, 18, 18, 31, 55, 55, 24, 24, 24, 24, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 5, 26, 35, 35, 35, 35, 35, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 5, 5, 5, 5, 5, 18, 18, 18, -100]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF5LWAHMqc9x",
        "outputId": "53be63e5-66d7-4ef0-f7ba-44d52ed4328c"
      },
      "source": [
        "! python sroie2019_dataset.py"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['id', 'tokens', 'ner_tags'],\n",
            "    num_rows: 124\n",
            "})\n",
            "Dataset({\n",
            "    features: ['id', 'tokens', 'ner_tags'],\n",
            "    num_rows: 124\n",
            "})\n",
            "Dataset({\n",
            "    features: ['id', 'tokens', 'ner_tags'],\n",
            "    num_rows: 124\n",
            "})\n",
            "List of tags:  ['B-AMOUNT', 'B-BANK_DETAILS', 'B-CGST', 'B-CUSTOMER_ADDRESS', 'B-CUSTOMER_EMAIL', 'B-CUSTOMER_NAME', 'B-CUSTOMER_PHONE', 'B-CUSTOMER_PO', 'B-DUE_DATE', 'B-GST', 'B-GSTIN', 'B-IGST', 'B-INVOICE_DATE', 'B-INVOICE_NUMBER', 'B-ITEM_DESCRIPTION', 'B-NOTES', 'B-PAYMENT_METHOD', 'B-PAYMENT_TERMS', 'B-QUANTITY', 'B-SGST', 'B-SUB-TOTAL', 'B-SUBTOTAL', 'B-TAX_AMOUNT', 'B-TOTAL_AMOUNT_DUE', 'B-TOTAL_PRICE', 'B-UNIT_PRICE', 'B-VENDOR_ADDRESS', 'B-VENDOR_EMAIL', 'B-VENDOR_NAME', 'B-VENDOR_PHONE', 'B-VENDOR_WEBSITE', 'I-AMOUNT', 'I-BANK_DETAILS', 'I-CUSTOMER_ADDRESS', 'I-CUSTOMER_EMAIL', 'I-CUSTOMER_NAME', 'I-CUSTOMER_PHONE', 'I-CUSTOMER_PO', 'I-DUE_DATE', 'I-GSTIN', 'I-INVOICE_DATE', 'I-INVOICE_NUMBER', 'I-ITEM_DESCRIPTION', 'I-NOTES', 'I-PAYMENT_METHOD', 'I-PAYMENT_TERMS', 'I-SUB-TOTAL', 'I-SUBTOTAL', 'I-TAX_AMOUNT', 'I-TOTAL_AMOUNT_DUE', 'I-VENDOR_ADDRESS', 'I-VENDOR_EMAIL', 'I-VENDOR_NAME', 'I-VENDOR_PHONE', 'I-VENDOR_WEBSITE', 'O']\n",
            "First sample:  {'id': '0', 'tokens': ['+91', '89012', '34567', 'AMOUNT', 'PAID', '=', '834.82', 'D-MART', 'PVT', 'LTD', '35/2867', 'B', '&', 'B2', 'Bypass', 'Road', 'Opp', 'Oberon', 'Mall', '41HHLWE12K4A1Q6', 'Edappally', 'Kochi', 'Kerala', '682024'], 'ner_tags': [55, 18, 18, 31, 55, 55, 24, 55, 55, 55, 55, 55, 55, 55, 5, 26, 35, 35, 35, 55, 5, 5, 5, 18]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foMBuqFBTwkT",
        "outputId": "6f28020c-fa00-4de9-f7f7-6f49b4dd680f",
        "collapsed": true
      },
      "source": [
        "! python hf_model_train.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-26 13:34:21.223558: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-26 13:34:21.263421: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-26 13:34:21.275067: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-26 13:34:23.498286: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/content/hf_model_train.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msvinayak994\u001b[0m (\u001b[33msparathon\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20241126_133428-2x8ugx79\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtest-ner\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/sparathon/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/sparathon/huggingface/runs/2x8ugx79\u001b[0m\n",
            "  2% 8/400 [02:47<2:09:05, 19.76s/it]\n",
            "  0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25% 2/8 [00:06<00:19,  3.19s/it]\u001b[A\n",
            " 38% 3/8 [00:14<00:26,  5.28s/it]\u001b[A\n",
            " 50% 4/8 [00:25<00:29,  7.46s/it]\u001b[A\n",
            " 62% 5/8 [00:33<00:22,  7.64s/it]\u001b[A\n",
            " 75% 6/8 [00:38<00:13,  6.81s/it]\u001b[A\n",
            " 88% 7/8 [00:46<00:07,  7.10s/it]\u001b[A\n",
            "100% 8/8 [00:50<00:00,  6.02s/it]\u001b[A/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 2.4380202293395996, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.5230372123037212, 'eval_runtime': 56.6321, 'eval_samples_per_second': 2.19, 'eval_steps_per_second': 0.141, 'epoch': 1.0}\n",
            "  2% 8/400 [03:44<2:09:05, 19.76s/it]\n",
            "100% 8/8 [00:50<00:00,  6.02s/it]\u001b[A\n",
            "  4% 16/400 [06:23<2:07:02, 19.85s/it]\n",
            "  0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25% 2/8 [00:07<00:22,  3.82s/it]\u001b[A\n",
            " 38% 3/8 [00:12<00:21,  4.38s/it]\u001b[A\n",
            " 50% 4/8 [00:20<00:22,  5.54s/it]\u001b[A\n",
            " 62% 5/8 [00:25<00:16,  5.37s/it]\u001b[A\n",
            " 75% 6/8 [00:33<00:12,  6.25s/it]\u001b[A\n",
            " 88% 7/8 [00:41<00:06,  6.72s/it]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 1.853420376777649, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.5230372123037212, 'eval_runtime': 51.421, 'eval_samples_per_second': 2.411, 'eval_steps_per_second': 0.156, 'epoch': 2.0}\n",
            "  4% 16/400 [07:15<2:07:02, 19.85s/it]\n",
            "100% 8/8 [00:45<00:00,  5.77s/it]\u001b[A\n",
            "  6% 24/400 [10:18<2:37:26, 25.12s/it]\n",
            "  0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25% 2/8 [00:12<00:37,  6.31s/it]\u001b[A\n",
            " 38% 3/8 [00:19<00:33,  6.67s/it]\u001b[A\n",
            " 50% 4/8 [00:30<00:33,  8.35s/it]\u001b[A\n",
            " 62% 5/8 [00:42<00:28,  9.51s/it]\u001b[A\n",
            " 75% 6/8 [00:53<00:20, 10.12s/it]\u001b[A\n",
            " 88% 7/8 [01:06<00:10, 10.82s/it]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 1.4724522829055786, 'eval_precision': 0.7250859106529209, 'eval_recall': 0.12454500737825873, 'eval_f1': 0.21257660985643526, 'eval_accuracy': 0.5746181974618197, 'eval_runtime': 87.5251, 'eval_samples_per_second': 1.417, 'eval_steps_per_second': 0.091, 'epoch': 3.0}\n",
            "  6% 24/400 [11:45<2:37:26, 25.12s/it]\n",
            "100% 8/8 [01:15<00:00, 10.05s/it]\u001b[A\n",
            "  8% 32/400 [14:44<2:26:35, 23.90s/it]\n",
            "  0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25% 2/8 [00:08<00:26,  4.34s/it]\u001b[A\n",
            " 38% 3/8 [00:13<00:23,  4.69s/it]\u001b[A\n",
            " 50% 4/8 [00:20<00:21,  5.43s/it]\u001b[A\n",
            " 62% 5/8 [00:26<00:16,  5.58s/it]\u001b[A\n",
            " 75% 6/8 [00:31<00:10,  5.42s/it]\u001b[A\n",
            " 88% 7/8 [00:39<00:06,  6.15s/it]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 1.152952790260315, 'eval_precision': 0.6926190797463231, 'eval_recall': 0.5049680275454993, 'eval_f1': 0.5840919435593992, 'eval_accuracy': 0.7063024306302431, 'eval_runtime': 50.4699, 'eval_samples_per_second': 2.457, 'eval_steps_per_second': 0.159, 'epoch': 4.0}\n",
            "  8% 32/400 [15:34<2:26:35, 23.90s/it]\n",
            "100% 8/8 [00:44<00:00,  5.49s/it]\u001b[A\n",
            " 10% 40/400 [18:18<2:01:37, 20.27s/it]\n",
            "  0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25% 2/8 [00:06<00:19,  3.19s/it]\u001b[A\n",
            " 38% 3/8 [00:13<00:24,  4.99s/it]\u001b[A\n",
            " 50% 4/8 [00:19<00:20,  5.05s/it]\u001b[A\n",
            " 62% 5/8 [00:24<00:15,  5.19s/it]\u001b[A\n",
            " 75% 6/8 [00:31<00:11,  5.82s/it]\u001b[A\n",
            " 88% 7/8 [00:36<00:05,  5.64s/it]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.9043949842453003, 'eval_precision': 0.6940121611872617, 'eval_recall': 0.6624692572552877, 'eval_f1': 0.6778739681900543, 'eval_accuracy': 0.7553452355345236, 'eval_runtime': 49.088, 'eval_samples_per_second': 2.526, 'eval_steps_per_second': 0.163, 'epoch': 5.0}\n",
            " 10% 40/400 [19:07<2:01:37, 20.27s/it]\n",
            "100% 8/8 [00:42<00:00,  5.29s/it]\u001b[A\n",
            " 11% 45/400 [20:49<2:21:24, 23.90s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python predict.py"
      ],
      "metadata": {
        "id": "iqNHp7kjgK8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python tfliteConvert.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-YU4qrIee-D",
        "outputId": "b24aeefc-012d-4519-b4cd-3711363f4a2c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-26 12:37:47.748702: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-26 12:37:47.795026: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-26 12:37:47.807341: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-26 12:37:47.854809: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-26 12:37:50.560012: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loading TensorFlow model...\n",
            "All PyTorch model weights were used when initializing TFDistilBertForTokenClassification.\n",
            "\n",
            "All the weights of TFDistilBertForTokenClassification were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForTokenClassification for predictions without further training.\n",
            "Converting to TFLite format...\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x780a392b0310>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x780a392b2ec0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x780a39469c60>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x780a38194af0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x780a381976a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x780a381a6290>, because it is not built.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "W0000 00:00:1732624730.137877   65943 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
            "W0000 00:00:1732624730.140993   65943 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
            "2024-11-26 12:38:50.144547: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpp7oyd3kh\n",
            "2024-11-26 12:38:50.178191: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
            "2024-11-26 12:38:50.178260: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpp7oyd3kh\n",
            "2024-11-26 12:38:50.373520: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
            "2024-11-26 12:38:50.405360: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
            "2024-11-26 12:38:51.313728: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpp7oyd3kh\n",
            "2024-11-26 12:38:51.531349: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 1386808 microseconds.\n",
            "2024-11-26 12:38:52.044677: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "Saving TFLite model to ./sroie2019v1.tflite...\n",
            "Conversion completed!\n",
            "TFLite model saved!\n"
          ]
        }
      ]
    }
  ]
}